{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Import libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lKBDkXSUz3an"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import random\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, GlobalAveragePooling1D, GlobalAveragePooling2D, Flatten, BatchNormalization, Dense\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "#from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import inspect\n",
    "import gc\n",
    "\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "#for data augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam, SGD , RMSprop\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jadDhNPo0MjD"
   },
   "source": [
    "<h2>2. Read Data and Data augmentation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abb--Cwa04Rg",
    "outputId": "cfecee64-4c90-4a49-cd65-204e1bb9fa51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#count the number of images in the dirictory\n",
    "def count_files(directory):\n",
    "    return sum([len(files) for r, d, files in os.walk(directory)])\n",
    "\n",
    "\n",
    "\n",
    "#paths to data\n",
    "train_data_dir = r\"data/train\"\n",
    "val_data_dir = r\"data/val\"\n",
    "test_data_dir = r\"data/test\"\n",
    "\n",
    "\n",
    "#scale images\n",
    "rescale = 1./255\n",
    "\n",
    "#some model parameters \n",
    "target_size = (150, 150)\n",
    "batch_size = 163\n",
    "class_mode = \"categorical\"\n",
    "\n",
    "\n",
    "#=============================== data augmentation========================\n",
    "gen_train = ImageDataGenerator(\n",
    "    rescale=rescale,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "train_augmented = gen_train.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "gen_val= ImageDataGenerator(rescale=rescale)\n",
    "\n",
    "validation_augmented = gen_val.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=count_files(val_data_dir),\n",
    "    shuffle = False)\n",
    "\n",
    "\n",
    "gen_test = ImageDataGenerator(rescale=rescale)\n",
    "\n",
    "test_augmented = gen_test.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=target_size,\n",
    "    class_mode=class_mode,\n",
    "    batch_size=count_files(test_data_dir),\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9mTN9bWO1DtG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PP0aGpsL1vIt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IgJhwP5C1u1a"
   },
   "outputs": [],
   "source": [
    "#=========================== callbacks=================\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=100,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKHkY_tk3BL2",
    "outputId": "ffca04f0-7dcc-49d2-9b4f-836bac0be8dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.9448173005219984, 1: 0.6730322580645162}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_augmented.classes),\n",
    "                                        y = train_augmented.classes                                                   \n",
    "                                    )\n",
    "class_weight = dict(zip(np.unique(train_augmented.classes), class_weights))\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wK5WHydy1utW"
   },
   "source": [
    "<h2>3. The CNN model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hP6d3lxr3t7i",
    "outputId": "ac7160cf-7574-4c71-e529-d9e673b2f8bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 4s - loss: 0.7260 - accuracy: 0.2883 - val_loss: 0.6931 - val_accuracy: 0.5000 - 4s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "1/1 - 3s - loss: 0.7211 - accuracy: 0.2945 - val_loss: 0.7267 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 3/100\n",
      "1/1 - 3s - loss: 0.7326 - accuracy: 0.3190 - val_loss: 0.6952 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 4/100\n",
      "1/1 - 3s - loss: 0.6932 - accuracy: 0.2577 - val_loss: 0.6924 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 5/100\n",
      "1/1 - 3s - loss: 0.6722 - accuracy: 0.2331 - val_loss: 0.6928 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 6/100\n",
      "1/1 - 3s - loss: 0.6717 - accuracy: 0.2331 - val_loss: 0.6927 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 7/100\n",
      "1/1 - 3s - loss: 0.6930 - accuracy: 0.8344 - val_loss: 0.6925 - val_accuracy: 0.5625 - 3s/epoch - 3s/step\n",
      "Epoch 8/100\n",
      "1/1 - 3s - loss: 0.7569 - accuracy: 0.4540 - val_loss: 0.6922 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 9/100\n",
      "1/1 - 3s - loss: 0.6769 - accuracy: 0.2393 - val_loss: 0.6920 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 10/100\n",
      "1/1 - 3s - loss: 0.6775 - accuracy: 0.2393 - val_loss: 0.6914 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 11/100\n",
      "1/1 - 3s - loss: 0.7046 - accuracy: 0.2761 - val_loss: 0.6907 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 12/100\n",
      "1/1 - 3s - loss: 0.6886 - accuracy: 0.2577 - val_loss: 0.6895 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 13/100\n",
      "1/1 - 3s - loss: 0.7230 - accuracy: 0.3129 - val_loss: 0.7008 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 14/100\n",
      "1/1 - 3s - loss: 0.6939 - accuracy: 0.2577 - val_loss: 0.6867 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 15/100\n",
      "1/1 - 3s - loss: 0.6974 - accuracy: 0.2883 - val_loss: 0.6795 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 16/100\n",
      "1/1 - 3s - loss: 0.6723 - accuracy: 0.2515 - val_loss: 0.6721 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 17/100\n",
      "1/1 - 3s - loss: 0.6504 - accuracy: 0.2270 - val_loss: 0.6642 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 18/100\n",
      "1/1 - 3s - loss: 0.6601 - accuracy: 0.2945 - val_loss: 0.7543 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 19/100\n",
      "1/1 - 3s - loss: 0.7279 - accuracy: 0.2209 - val_loss: 0.6657 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 20/100\n",
      "1/1 - 3s - loss: 0.6683 - accuracy: 0.7546 - val_loss: 0.6864 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 21/100\n",
      "1/1 - 3s - loss: 0.7018 - accuracy: 0.7546 - val_loss: 0.6917 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 22/100\n",
      "1/1 - 3s - loss: 0.7000 - accuracy: 0.7362 - val_loss: 0.6930 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 23/100\n",
      "1/1 - 3s - loss: 0.6534 - accuracy: 0.7853 - val_loss: 0.6933 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 24/100\n",
      "1/1 - 3s - loss: 0.6766 - accuracy: 0.7607 - val_loss: 0.6934 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 25/100\n",
      "1/1 - 3s - loss: 0.7710 - accuracy: 0.6626 - val_loss: 0.6933 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 26/100\n",
      "1/1 - 3s - loss: 0.7178 - accuracy: 0.7178 - val_loss: 0.6933 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 27/100\n",
      "1/1 - 2s - loss: 0.6588 - accuracy: 0.7791 - val_loss: 0.6933 - val_accuracy: 0.5000 - 2s/epoch - 2s/step\n",
      "Epoch 28/100\n",
      "1/1 - 3s - loss: 0.7351 - accuracy: 0.6994 - val_loss: 0.6932 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 29/100\n",
      "1/1 - 3s - loss: 0.6997 - accuracy: 0.7362 - val_loss: 0.6931 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 30/100\n",
      "1/1 - 3s - loss: 0.6647 - accuracy: 0.7730 - val_loss: 0.6930 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 31/100\n",
      "1/1 - 3s - loss: 0.7461 - accuracy: 0.6871 - val_loss: 0.6929 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 32/100\n",
      "1/1 - 3s - loss: 0.6705 - accuracy: 0.7669 - val_loss: 0.6928 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 33/100\n",
      "1/1 - 3s - loss: 0.7222 - accuracy: 0.7117 - val_loss: 0.6927 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 34/100\n",
      "1/1 - 3s - loss: 0.7104 - accuracy: 0.7239 - val_loss: 0.6924 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 35/100\n",
      "1/1 - 3s - loss: 0.7155 - accuracy: 0.7178 - val_loss: 0.6919 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 36/100\n",
      "1/1 - 2s - loss: 0.6812 - accuracy: 0.7546 - val_loss: 0.6914 - val_accuracy: 0.5000 - 2s/epoch - 2s/step\n",
      "Epoch 37/100\n",
      "1/1 - 3s - loss: 0.6759 - accuracy: 0.7669 - val_loss: 0.6911 - val_accuracy: 0.6875 - 3s/epoch - 3s/step\n",
      "Epoch 38/100\n",
      "1/1 - 3s - loss: 0.6917 - accuracy: 0.5828 - val_loss: 0.6901 - val_accuracy: 0.6875 - 3s/epoch - 3s/step\n",
      "Epoch 39/100\n",
      "1/1 - 3s - loss: 0.7225 - accuracy: 0.6196 - val_loss: 0.6894 - val_accuracy: 0.5625 - 3s/epoch - 3s/step\n",
      "Epoch 40/100\n",
      "1/1 - 3s - loss: 0.6991 - accuracy: 0.3926 - val_loss: 0.6879 - val_accuracy: 0.5625 - 3s/epoch - 3s/step\n",
      "Epoch 41/100\n",
      "1/1 - 3s - loss: 0.6779 - accuracy: 0.3067 - val_loss: 0.6847 - val_accuracy: 0.6875 - 3s/epoch - 3s/step\n",
      "Epoch 42/100\n",
      "1/1 - 4s - loss: 0.6785 - accuracy: 0.5767 - val_loss: 0.6804 - val_accuracy: 0.8125 - 4s/epoch - 4s/step\n",
      "Epoch 43/100\n",
      "1/1 - 2s - loss: 0.6575 - accuracy: 0.7362 - val_loss: 0.6718 - val_accuracy: 0.6875 - 2s/epoch - 2s/step\n",
      "Epoch 44/100\n",
      "1/1 - 3s - loss: 0.6581 - accuracy: 0.4724 - val_loss: 0.6598 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 45/100\n",
      "1/1 - 3s - loss: 0.6447 - accuracy: 0.6933 - val_loss: 0.6596 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 46/100\n",
      "1/1 - 3s - loss: 0.6485 - accuracy: 0.3067 - val_loss: 0.6654 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 47/100\n",
      "1/1 - 3s - loss: 0.6966 - accuracy: 0.8160 - val_loss: 0.6090 - val_accuracy: 0.6875 - 3s/epoch - 3s/step\n",
      "Epoch 48/100\n",
      "1/1 - 3s - loss: 0.5974 - accuracy: 0.6380 - val_loss: 0.6715 - val_accuracy: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 49/100\n",
      "1/1 - 3s - loss: 0.6385 - accuracy: 0.3252 - val_loss: 0.6424 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 50/100\n",
      "1/1 - 3s - loss: 0.6184 - accuracy: 0.8528 - val_loss: 0.6628 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 51/100\n",
      "1/1 - 3s - loss: 0.6326 - accuracy: 0.8037 - val_loss: 0.6313 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 52/100\n",
      "1/1 - 3s - loss: 0.6354 - accuracy: 0.8160 - val_loss: 0.5349 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 53/100\n",
      "1/1 - 3s - loss: 0.5521 - accuracy: 0.6994 - val_loss: 0.6327 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 54/100\n",
      "1/1 - 3s - loss: 0.7164 - accuracy: 0.4049 - val_loss: 0.5421 - val_accuracy: 0.6875 - 3s/epoch - 3s/step\n",
      "Epoch 55/100\n",
      "1/1 - 3s - loss: 0.5423 - accuracy: 0.7975 - val_loss: 0.6556 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 56/100\n",
      "1/1 - 3s - loss: 0.6520 - accuracy: 0.7423 - val_loss: 0.6890 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 57/100\n",
      "1/1 - 3s - loss: 0.6149 - accuracy: 0.8098 - val_loss: 0.6474 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 58/100\n",
      "1/1 - 3s - loss: 0.5410 - accuracy: 0.8773 - val_loss: 0.5172 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 59/100\n",
      "1/1 - 3s - loss: 0.5089 - accuracy: 0.8282 - val_loss: 0.4227 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 60/100\n",
      "1/1 - 4s - loss: 0.5619 - accuracy: 0.5583 - val_loss: 0.3918 - val_accuracy: 0.8125 - 4s/epoch - 4s/step\n",
      "Epoch 61/100\n",
      "1/1 - 3s - loss: 0.5148 - accuracy: 0.5890 - val_loss: 0.4810 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 62/100\n",
      "1/1 - 3s - loss: 0.4207 - accuracy: 0.7914 - val_loss: 0.7728 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 63/100\n",
      "1/1 - 3s - loss: 0.4827 - accuracy: 0.8282 - val_loss: 0.8909 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 64/100\n",
      "1/1 - 3s - loss: 0.4219 - accuracy: 0.8773 - val_loss: 0.4882 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 65/100\n",
      "1/1 - 3s - loss: 0.3898 - accuracy: 0.7362 - val_loss: 0.9001 - val_accuracy: 0.6875 - 3s/epoch - 3s/step\n",
      "Epoch 66/100\n",
      "1/1 - 2s - loss: 0.3133 - accuracy: 0.8773 - val_loss: 1.0538 - val_accuracy: 0.6875 - 2s/epoch - 2s/step\n",
      "Epoch 67/100\n",
      "1/1 - 3s - loss: 0.4498 - accuracy: 0.8834 - val_loss: 0.3469 - val_accuracy: 0.8750 - 3s/epoch - 3s/step\n",
      "Epoch 68/100\n",
      "1/1 - 3s - loss: 0.6826 - accuracy: 0.6012 - val_loss: 0.7177 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 69/100\n",
      "1/1 - 3s - loss: 0.3379 - accuracy: 0.8896 - val_loss: 1.0356 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 70/100\n",
      "1/1 - 3s - loss: 0.3910 - accuracy: 0.8957 - val_loss: 0.8164 - val_accuracy: 0.6250 - 3s/epoch - 3s/step\n",
      "Epoch 71/100\n",
      "1/1 - 2s - loss: 0.4948 - accuracy: 0.8589 - val_loss: 0.4792 - val_accuracy: 0.8125 - 2s/epoch - 2s/step\n",
      "Epoch 72/100\n",
      "1/1 - 2s - loss: 0.3052 - accuracy: 0.8650 - val_loss: 0.4104 - val_accuracy: 0.7500 - 2s/epoch - 2s/step\n",
      "Epoch 73/100\n",
      "1/1 - 3s - loss: 0.3765 - accuracy: 0.7730 - val_loss: 0.4094 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 74/100\n",
      "1/1 - 3s - loss: 0.3750 - accuracy: 0.7485 - val_loss: 0.4102 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 75/100\n",
      "1/1 - 3s - loss: 0.4768 - accuracy: 0.6074 - val_loss: 0.3999 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 76/100\n",
      "1/1 - 3s - loss: 0.3912 - accuracy: 0.7730 - val_loss: 0.4060 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 77/100\n",
      "1/1 - 3s - loss: 0.3133 - accuracy: 0.8282 - val_loss: 0.4780 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 78/100\n",
      "1/1 - 3s - loss: 0.4450 - accuracy: 0.8405 - val_loss: 0.5197 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 79/100\n",
      "1/1 - 4s - loss: 0.2795 - accuracy: 0.9264 - val_loss: 0.5494 - val_accuracy: 0.7500 - 4s/epoch - 4s/step\n",
      "Epoch 80/100\n",
      "1/1 - 3s - loss: 0.4599 - accuracy: 0.8650 - val_loss: 0.4267 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 81/100\n",
      "1/1 - 3s - loss: 0.2773 - accuracy: 0.8834 - val_loss: 0.3618 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 82/100\n",
      "1/1 - 3s - loss: 0.2881 - accuracy: 0.8466 - val_loss: 0.3426 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 83/100\n",
      "1/1 - 3s - loss: 0.4317 - accuracy: 0.7607 - val_loss: 0.4508 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 84/100\n",
      "1/1 - 3s - loss: 0.2190 - accuracy: 0.8773 - val_loss: 0.8148 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 85/100\n",
      "1/1 - 3s - loss: 0.3934 - accuracy: 0.8834 - val_loss: 0.9088 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 86/100\n",
      "1/1 - 3s - loss: 0.3626 - accuracy: 0.9264 - val_loss: 0.6444 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 87/100\n",
      "1/1 - 3s - loss: 0.2929 - accuracy: 0.9018 - val_loss: 0.4221 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 88/100\n",
      "1/1 - 3s - loss: 0.2471 - accuracy: 0.8589 - val_loss: 0.3516 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 89/100\n",
      "1/1 - 3s - loss: 0.4260 - accuracy: 0.7239 - val_loss: 0.4245 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 90/100\n",
      "1/1 - 3s - loss: 0.4102 - accuracy: 0.8098 - val_loss: 0.5637 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 91/100\n",
      "1/1 - 3s - loss: 0.3670 - accuracy: 0.8344 - val_loss: 0.5311 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 92/100\n",
      "1/1 - 3s - loss: 0.2915 - accuracy: 0.8834 - val_loss: 0.4441 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 93/100\n",
      "1/1 - 3s - loss: 0.3214 - accuracy: 0.8528 - val_loss: 0.3944 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 94/100\n",
      "1/1 - 3s - loss: 0.3222 - accuracy: 0.8589 - val_loss: 0.3475 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 95/100\n",
      "1/1 - 3s - loss: 0.2795 - accuracy: 0.8896 - val_loss: 0.3284 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 96/100\n",
      "1/1 - 3s - loss: 0.3151 - accuracy: 0.8098 - val_loss: 0.3198 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n",
      "Epoch 97/100\n",
      "1/1 - 4s - loss: 0.3098 - accuracy: 0.8466 - val_loss: 0.3258 - val_accuracy: 0.7500 - 4s/epoch - 4s/step\n",
      "Epoch 98/100\n",
      "1/1 - 3s - loss: 0.3174 - accuracy: 0.8221 - val_loss: 0.3444 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 99/100\n",
      "1/1 - 3s - loss: 0.2311 - accuracy: 0.8896 - val_loss: 0.3936 - val_accuracy: 0.7500 - 3s/epoch - 3s/step\n",
      "Epoch 100/100\n",
      "1/1 - 3s - loss: 0.2756 - accuracy: 0.8773 - val_loss: 0.4169 - val_accuracy: 0.8125 - 3s/epoch - 3s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding=\"same\", input_shape=(3,150,150)))\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding=\"same\", input_shape=(3,150,150)))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(96, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(96, (3, 3), padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), dilation_rate=(2, 2), activation='relu', padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"valid\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(2 , activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizers.Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "steps_per_epoch=len(test_augmented)\n",
    "validation_steps=len(validation_augmented)\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_augmented,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=100,\n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=validation_augmented,\n",
    "    validation_steps=validation_steps, \n",
    "    class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Egx4F__EDDDB",
    "outputId": "a12ce981-3c61-42c2-c291-d65cf174e477"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step - loss: 0.3904 - accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "#history.history['accuracy']\n",
    "\n",
    "result  = model.evaluate_generator(test_augmented, steps=len(test_augmented), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neSiRL41y6l8"
   },
   "source": [
    "<h2>4. VGG16</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bO45dcWv3cl-"
   },
   "outputs": [],
   "source": [
    "# Load and configure model InceptionV3 for fine-tuning with new class labels\n",
    "inputs = keras.Input(shape=(3, 224, 224))\n",
    "input_shape = (3, 224, 224)   \n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "out = base_model.output\n",
    "\n",
    "\n",
    "results = Dense(2, activation='softmax')(x) \n",
    "    \n",
    "    \n",
    "TFmodel = Model(inputs= inputs, outputs=results)\n",
    "    \n",
    "    \n",
    "for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "        \n",
    "    \n",
    "TFmodel.compile(optimizers.Adam(lr = 0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "steps_per_epoch=len(test_augmented)\n",
    "validation_steps=len(validation_augmented)\n",
    "\n",
    "\n",
    "history = TFmodel.fit_generator(\n",
    "    train_augmented,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=validation_augmented,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight)\n",
    "        \n",
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
